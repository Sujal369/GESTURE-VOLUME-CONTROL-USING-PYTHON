# GESTURE-VOLUME-CONTROL-USING-PYTHON
It is gesture volume control python program . It's very easy to use and very interactive.

# INTRODUCTION
Gesture recognition helps computers to understand human body language. This helps to build a more potent link between humans and machines, rather than just the basic text user interfaces or graphical user interfaces (GUIs). In this project for gesture recognition, the human bodyâ€™s motions are read by computer camera. Thecomputer then makes use of this data as input to handle applications. The objective of this project is to develop an interface which will capture human hand gesture dynamically and will control the volume level.

NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.

Pycaw : Python Audio Control Library

Mediapipe is an open-source machine learning library of Google, which has some solutions for face recognition and gesture recognition, and provides encapsulation of python, js and other languages. MediaPipe Hands is a high-fidelity hand and finger tracking solution. It uses machine learning (ML) to infer 21 key 3D hand information from just one frame. We can use it to extract the coordinates of the key points of the hand.


# Volume Control With Hand Detection OpenCV Python With Source Code
The Volume Control With Hand Detection OpenCV Python was developed using Python OpenCV, In this Python OpenCV Project With Source Code we are going Building a Volume Controller with OpenCV , To change the volume of a computer.

We first look into hand tracking and then we will use the hand landmarks to find gesture of our hand to change the volume. This project is module based which means we will be using a previously created hand module which makes the hand tracking very easy.

# What is OpenCV?
OpenCV is short for Open Source Computer Vision. Intuitively by the name, it is an open-source Computer Vision and Machine Learning library. This library is capable of processing real-time image and video while also boasting analytical capabilities. It supports the Deep Learning frameworks.

# WORKING PRINCIPLE
The camera in our device is used for this project. It detects our hand with points in it so as it can see the distance between our thumb finger tip and index finger tip. The distance between the points 4 and 8 is directly proportional to the volume of device

# ADVANTAGES:
Easy to use
Hassle free
Fun to use
More interactive

# DISADVANTAGES:
Cant be used for long distance
Sometimes not accurate
Requires a decent camera
May be confused by two palms

# Steps to execute a program :

1.We need to install the libraries we will use in our project.
2.Importing the libraries we will need
3.Detecting, initializing, and configuring the hands
4.Accessing the speaker using pycaw
5.Capturing an image from our camera and converting it to an RGB image
6.Checking whether we have multiple hands in our input
7.Finally execute the code.








